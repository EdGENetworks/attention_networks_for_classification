[DataAndPreprocessing]
train_path = dataset/dev.pkl
dev_path = dataset/dev.pkl
test_path = dataset/test.pkl
write_data_dir = dataset/reuters
word_vec_path = word vectors/cc.en.300.bin
preload_word_to_idx = true
word_to_idx_path = ulmfit/ulmfit_word_to_idx.json #dataset/reuters/word_to_idx.json #
label_to_idx_path = dataset/reuters/label_to_idx.json
#label_map_path =
min_freq_word = 5

[Training]
train_batch_size = 16
eval_batch_size = 32
learning_rate = 0.001
dropout = 0.5
num_train_epochs = 1
eval_every = 45
K = 1 #TODO: propagation
weight_decay = 0.001
binary_class = true #TODO: propagation

[Model]
model_name = HCapsNet
word_encoder = ulmfit
sent_encoder = gru
use_glove = True
embed_dim = 300
word_hidden = 100
sent_hidden = 500

[CapsNet]
dim_caps = 16
num_caps = 32
num_compressed_caps = 65
num_head_doc = 5

[FastText]
create_wordvecs = false
autotune_time_fasttext = 600
#TODO: add hyperparams for creation of word vecs

[ULMFiT]
ulmfit_pretrained_path = ulmfit/lm_torch3.pt
dropout_factor = 1.0
